{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Feature Engineering?\n",
    "\n",
    "Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.\n",
    "\n",
    "feature engineering is manually designing what the input xâ€™s should be\n",
    "\n",
    "## Feature: An attribute useful for your modeling task\n",
    "\n",
    "feature is an individual measurable property or characteristic of a phenomenon being observed. Choosing informative, discriminating and independent features is a crucial step for effective algorithms in pattern recognition, classification and regression. Features are usually numeric, but structural features such as strings and graphs are used in syntactic pattern recognition.\n",
    "\n",
    "## Feature Importance: An estimate of the usefulness of a feature\n",
    "\n",
    "## Feature Extraction: The automatic construction of new features from raw data\n",
    "\n",
    " Feature extraction is a process of automatically reducing the dimensionality of these types of observations into a much smaller set that can be modelled\n",
    " \n",
    " ## Feature Selection: From many features to a few that are useful\n",
    "\n",
    "Those attributes that are irrelevant to the problem need to be removed. There will be some features that will be more important than others to the model accuracy. There will also be features that will be redundant in the context of other features.\n",
    "\n",
    "## Techniques in Feature Selection:\n",
    " \n",
    "### Filter Methods:\n",
    "    -Information Gain(IG)\n",
    "    \n",
    "    -Chi-Square Test\n",
    "    \n",
    "    -Correlation Coeff\n",
    "    \n",
    "### Wrapper Method:\n",
    "    -Recursive Feature Elimination\n",
    "    \n",
    "    -Genetic Algorithms\n",
    "    \n",
    "### Embedded Methods:\n",
    "    -Decision Tree\n",
    "    \n",
    "## Feature Construction: The manual construction of new features from raw data\n",
    "\n",
    "### Missing Data Imputation:\n",
    "\n",
    "    Complete case analysis\n",
    "\n",
    "    Mean / Median / Mode imputation\n",
    "\n",
    "    Random Sample Imputation\n",
    "\n",
    "    Replacement by Arbitrary Value\n",
    "\n",
    "    Missing Value Indicator\n",
    "\n",
    "    Multivariate imputation\n",
    "    \n",
    "\n",
    "### Categorical Encoding:\n",
    "\n",
    "    One hot encoding\n",
    "\n",
    "    Count and Frequency encoding\n",
    "\n",
    "    Target encoding / Mean encoding\n",
    "\n",
    "    Ordinal encoding\n",
    "\n",
    "    Weight of Evidence\n",
    "\n",
    "    Rare label encoding\n",
    "\n",
    "    BaseN, feature hashing and others\n",
    "    \n",
    "\n",
    "### Variable Transformation:\n",
    "\n",
    "    Logarithm\n",
    "\n",
    "    Reciprocal\n",
    "\n",
    "    Square root\n",
    "\n",
    "    Exponential\n",
    "\n",
    "    Yeo-Johnson\n",
    "\n",
    "    Box-Cox\n",
    "\n",
    "\n",
    "### Discretisation:\n",
    "\n",
    "    Equal frequency discretisation\n",
    "\n",
    "    Equal length discretisation\n",
    "\n",
    "    Discretisation with trees\n",
    "\n",
    "    Discretisation with ChiMerge\n",
    "\n",
    "\n",
    "### Outlier Removal:\n",
    "\n",
    "    Removing outliers\n",
    "\n",
    "    Treating outliers as NaN\n",
    "\n",
    "    Capping, Windsorisation\n",
    "    \n",
    "\n",
    "### Feature Scaling:\n",
    "\n",
    "    Standardisation\n",
    "\n",
    "    MinMax Scaling\n",
    "\n",
    "    Mean Scaling\n",
    "\n",
    "    Max Absolute Scaling\n",
    "\n",
    "    Unit norm-Scaling\n",
    "    \n",
    "\n",
    "### Date and Time Engineering:\n",
    "\n",
    "    Extracting days, months, years, quarters, time elapsed\n",
    "    \n",
    "### Feature Creation:\n",
    "\n",
    "    Sum, subtraction, mean, min, max, product, quotient of group of features\n",
    "    \n",
    "### Aggregating Transaction Data:\n",
    "\n",
    "    Same as above but in same feature over time window\n",
    "    \n",
    "### Extracting features from text:\n",
    "\n",
    "    Bag of words\n",
    "\n",
    "    tfidf\n",
    "\n",
    "    n-grams\n",
    "\n",
    "    word2vec\n",
    "\n",
    "    topic extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
